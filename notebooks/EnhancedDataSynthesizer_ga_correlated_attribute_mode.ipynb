{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('..') # to import local EnhancedDataSynthesizer version\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('classic')\n",
    "\n",
    "from DataSynthesizer.DataDescriber import DataDescriber\n",
    "from DataSynthesizer.DataGenerator import DataGenerator\n",
    "from DataSynthesizer.lib.utils import display_bayesian_network\n",
    "\n",
    "from DataSynthesizer.lib.utils import mutual_information\n",
    "\n",
    "from DataSynthesizer.federated_utils.evaluation import TaskUtility, HistogramAndHeatmapComparison\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "file_path=os.getcwd() \n",
    "traindata = os.path.join(file_path+'/data/',\"adult_complete.csv\")\n",
    "testdata = os.path.join(file_path+'/data/',\"adult_test.csv\")\n",
    "\n",
    "data=traindata\n",
    "diff=0\n",
    "k=2\n",
    "sensi=None \n",
    "#sensi='relationship'\n",
    "target='income'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Constructing Bayesian Network (BN) ================\n",
      "Adding ROOT race\n",
      "Adding attribute native-country\n",
      "Adding attribute education-num\n",
      "Adding attribute occupation\n",
      "Adding attribute workclass\n",
      "Adding attribute age\n",
      "Adding attribute marital-status\n",
      "Adding attribute relationship\n",
      "Adding attribute sex\n",
      "Adding attribute hours-per-week\n",
      "Adding attribute income\n",
      "Adding attribute capital-gain\n",
      "Adding attribute capital-loss\n",
      "========================== BN constructed ==========================\n",
      "Wrote network to c:\\Users\\DMartinez\\Documents\\Repositories\\EnhancedDataSynthesizer\\notebooks\\out/correlated_attribute_mode/ga_corrmeta.json\n",
      "Runtime Data Description: 259.8283190727234\n",
      "Fitness: 3.2861418606177883\n",
      "Constructed Bayesian network:\n",
      "    native-country has parents ['race'].\n",
      "    education-num  has parents ['native-country', 'race'].\n",
      "    occupation     has parents ['education-num', 'native-country'].\n",
      "    workclass      has parents ['occupation', 'education-num'].\n",
      "    age            has parents ['occupation', 'education-num'].\n",
      "    marital-status has parents ['age', 'occupation'].\n",
      "    relationship   has parents ['marital-status', 'age'].\n",
      "    sex            has parents ['relationship', 'occupation'].\n",
      "    hours-per-week has parents ['age', 'occupation'].\n",
      "    income         has parents ['relationship', 'education-num'].\n",
      "    capital-gain   has parents ['income', 'relationship'].\n",
      "    capital-loss   has parents ['age', 'education-num'].\n"
     ]
    }
   ],
   "source": [
    "#output_dir = 'out/correlated_attribute_mode_ga/'\n",
    "output_dir = 'out/correlated_attribute_mode/'\n",
    "\n",
    "description_file_ga = os.path.join(file_path, output_dir, \"ga_corrmeta.json\")\n",
    "\n",
    "if sensi:\n",
    "    synthetic_data = os.path.join(file_path, output_dir, \"DSv_custom_\"+str(k)+\"_syntraindata.csv\")\n",
    "else:\n",
    "    synthetic_data = os.path.join(file_path, output_dir, \"DSv_\"+str(k)+\"_syntraindata.csv\")\n",
    "\n",
    "input_df = pd.read_csv(data, skipinitialspace=True)\n",
    "test_df = pd.read_csv(testdata, skipinitialspace=True)\n",
    "\n",
    "# An attribute is categorical if its domain size is less than this threshold.\n",
    "# Here modify the threshold to adapt to the domain size of \"education\" (which is 14 in input dataset).\n",
    "threshold_value = 20\n",
    "\n",
    "# Specify categorical attributes\n",
    "categorical_attributes = {'workclass': True, 'education-num': True, 'marital-status': True, 'occupation': True, 'relationship': True,\n",
    "                          'race': True, 'sex': True, 'native-country': True, 'income': True}\n",
    "\n",
    "# Specify which attributes are candidate keys of input dataset.\n",
    "candidate_keys = {}\n",
    "\n",
    "# A parameter in Differential Privacy. It roughly means that changing a row in the input dataset will not\n",
    "# change the probability of getting the same output more than a multiplicative difference of exp(epsilon).\n",
    "# Increase epsilon value to reduce the injected noises. Set epsilon=0 to turn off differential privacy.\n",
    "epsilon = diff\n",
    "\n",
    "# The maximum number of parents in Bayesian network, i.e., the maximum number of incoming edges.\n",
    "degree_of_bayesian_network = k\n",
    "\n",
    "# Number of tuples generated in synthetic dataset.\n",
    "num_tuples_to_generate = len(input_df)\n",
    "\n",
    "start=time.time()\n",
    "\n",
    "#Data Describer:\n",
    "describer_ga = DataDescriber(category_threshold=threshold_value)\n",
    "#describer_ga.describe_dataset_in_correlated_attribute_mode_ga(dataset_file=data,\n",
    "describer_ga.describe_dataset_in_correlated_attribute_mode(dataset_file=data,\n",
    "                                                    epsilon=epsilon,\n",
    "                                                    k=degree_of_bayesian_network,\n",
    "                                                    attribute_to_is_categorical=categorical_attributes,\n",
    "                                                    attribute_to_is_candidate_key=candidate_keys,\n",
    "                                                    #source_genes=10,\n",
    "                                                    #genepool_size=200,\n",
    "                                                    #epochs=400,\n",
    "                                                    #sensi=sensi,\n",
    "                                                    #target=target\n",
    "                                                    )\n",
    "\n",
    "describer_ga.save_dataset_description_to_file(description_file_ga)\n",
    "print(\"Wrote network to \" + description_file_ga)\n",
    "\n",
    "end=time.time()\n",
    "bn_time=end-start\n",
    "print(\"Runtime Data Description:\", bn_time)\n",
    "\n",
    "network=describer_ga.bayesian_network\n",
    "\n",
    "fitness = 0\n",
    "for (c, ps) in network:\n",
    "        for p in ps:\n",
    "            fitness += mutual_information(input_df[c], input_df[[p]])\n",
    "print(\"Fitness:\", fitness)\n",
    "\n",
    "display_bayesian_network(describer_ga.bayesian_network)\n",
    "start=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime Data Generation: 17.341266632080078\n"
     ]
    }
   ],
   "source": [
    "#Data Generator:\n",
    "ga_generator = DataGenerator()\n",
    "ga_generator.generate_dataset_in_correlated_attribute_mode(num_tuples_to_generate, description_file_ga)\n",
    "ga_generator.save_synthetic_data(synthetic_data)\n",
    "\n",
    "end=time.time()\n",
    "gen_time=end-start\n",
    "print(\"Runtime Data Generation:\", gen_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_df = pd.read_csv(synthetic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = True\n",
    "# if output:\n",
    "#             textf = os.path.join(output_dir, 'k_'+str(degree_of_bayesian_network)+'_epochs_'+str(400)+'.txt')\n",
    "#             with open(textf, 'w') as w:\n",
    "#                 w.write(\"================\"+'\\n'+\n",
    "#                         \"Runtime Data Description: \"+str(bn_time)+'\\n'+\n",
    "#                         \"Fitness: \"+str(fitness)+'\\n'+\n",
    "#                         \"Runtime Data Generation: \"+str(gen_time)+'\\n'\n",
    "#                         )\n",
    "\n",
    "#             syn_df = pd.read_csv(synthetic_data)\n",
    "\n",
    "#             # Label Encoding\n",
    "#             header = list(input_df.columns.values)\n",
    "\n",
    "#             for i in range(len(header)):\n",
    "\n",
    "#                 if header[i] in ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country', 'income']:\n",
    "#                     input_df.iloc[:,i]=le.fit_transform(list(input_df.iloc[:,i])).astype(float)\n",
    "#                     syn_df.iloc[:,i]=le.fit_transform(list(syn_df.iloc[:,i])).astype(float)\n",
    "\n",
    "#             header= ['age', 'wcl', 'edu', 'mst', 'occ', 'rel', 'rac', 'sex', 'cga', 'clo', 'hpw', 'nat', 'inc']\n",
    "#             correlations_syn = syn_df.corr()\n",
    "#             fig = plt.figure()\n",
    "#             ax = fig.add_subplot(1,1,1)\n",
    "#             cax = ax.matshow(correlations_syn, cmap='seismic', vmin=-1, vmax=1)\n",
    "#             ticks = np.arange(0,len(header),1)\n",
    "#             ax.set_xticks(ticks)\n",
    "#             ax.set_yticks(ticks)\n",
    "#             ax.set_xticklabels(header)\n",
    "#             ax.set_yticklabels(header)\n",
    "#             #ax.set_xlabel(\"DataSynthesizer with \\u03B5=\"+str(diff))\n",
    "#             plt.savefig(output_dir+'heatsyn_custom_rel.png', bbox_inches='tight')\n",
    "#             plt.show()\n",
    "\n",
    "#             correlations_real = input_df.corr()\n",
    "#             fig = plt.figure()\n",
    "#             ax = fig.add_subplot(1,1,1)\n",
    "#             cax = ax.matshow(correlations_real, cmap='seismic', vmin=-1, vmax=1)\n",
    "#             fig.colorbar(cax)\n",
    "#             ticks = np.arange(0,len(header),1)\n",
    "#             ax.set_xticks(ticks)\n",
    "#             ax.set_yticks(ticks)\n",
    "#             ax.set_xticklabels(header)\n",
    "#             ax.set_yticklabels(header)\n",
    "#             ax.set_xlabel(\"Original\")\n",
    "#             plt.savefig(output_dir+'heatreal.png', bbox_inches='tight')\n",
    "#             plt.show()\n",
    "\n",
    "#             for i in range(len(header)):\n",
    "#                 plt.hist(input_df.iloc[:,i], color='green', label='Original: '+header[i])\n",
    "#                 plt.legend()\n",
    "#                 plt.hist(syn_df.iloc[:,i],histtype='step', color='blue', label='DS with \\u03B5='+str(diff)+': '+header[i])\n",
    "#                 plt.legend()\n",
    "#                 plt.savefig(output_dir+'histograms/'+header[i]+'.png', bbox_inches='tight')\n",
    "#                 plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DMartinez\\Documents\\Repositories\\EnhancedDataSynthesizer\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\DMartinez\\Documents\\Repositories\\EnhancedDataSynthesizer\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "output=True\n",
    "if output: \n",
    "    HistogramAndHeatmapComparison(data, synthetic_data, output_dir)\n",
    "    TaskUtility(input_df,syn_df,test_df,target,output_dir,'Classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
